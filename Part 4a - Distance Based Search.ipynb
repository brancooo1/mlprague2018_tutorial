{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Songs on Spotify - Part 1: Distance Based Search\n",
    "\n",
    "The first part of this tutorial series demonstrates the traditional way of extracting features from the audio content, training a classifier and predicting results. Because we do not have access to the raw audio content, we cannot extract features ourselves. Fortunately, Spotify is so generious to provide extracted features via their API. Those are just low-level audio features, but they are more than any other streaming music service provide - so Kudos to Spotify for this API! To download the features from the Spotify API you need to apply for a valid client ID. Please follow the steps on the Github page to apply for such an ID.\n",
    "\n",
    "\n",
    "## Part 1 - Overview\n",
    "\n",
    "1. Introductions & Requirements\n",
    "2. Accessing the Spotify API\n",
    "3. Loading data\n",
    "4. Preprocess data\n",
    "5. Define the Similarity Model\n",
    "6. Optimize the Model\n",
    "7. Evaluate the Models\n",
    "\n",
    "\n",
    "# Short Introduction to Music Similarity Retrieval\n",
    "\n",
    "The objective of Music Similarity estimation or retrieval is to estimate the notion of similarity between two given tracks. A central part of such an approaches is the definition of a measure for similarity which is further affected by the approach taken to extract the relevant information. One approach is to analyze contextual data such as user generated listening behaviour data (e.g. play/skip-counts, user-tags, ratings, etc.). The approach followed by this tutorial is based on the music content itself and largely focuses on the notion of *acoustic similarity*. Music features are extracted from the audio content. The resulting music descriptors are high-dimensional numeric vectors and the accumulation of all feature vectors of a collection forms a vector-space. The general principle of content based similarity estimations is based on the assumption that numerical differences are an expression of perceptual dissimilarity. Different metrics such as the Manhattan (L1) or the Euclidean Distance (L2) or non-metric similarity functions such as the Kullback-Leibler divergence are used to estimate the numerical similarity of the feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "Please follow the instructions on the tutorial's Github page (https://github.com/slychief/tutorials/tree/master/spotify_similarity_search) to install the following dependencies to run this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:32.488000Z",
     "start_time": "2017-08-24T10:20:32.483000Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# numeric and scientific processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spotipy**\n",
    "\n",
    "Spotipy is a thin client library for the Spotify Web API.\n",
    "\n",
    "https://github.com/plamere/spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import spotipy.util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the following two variables according the credentials you received from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:33.260000Z",
     "start_time": "2017-08-24T10:20:33.256000Z"
    }
   },
   "outputs": [],
   "source": [
    "# only valid for MLPrague 2018 Deep Learning for Music Workshop\n",
    "\n",
    "SPOTIFY_USER = \"\"\n",
    "\n",
    "os.environ[\"SPOTIPY_CLIENT_ID\"]     = \"15ed4673698f4a1684cc74cf7b487662\"\n",
    "os.environ[\"SPOTIPY_CLIENT_SECRET\"] = \"91d6c3216ed94000b1035846d2e493a0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get the following message:\n",
    "\n",
    "    User authentication requires interaction with your\n",
    "    web browser. Once you enter your credentials and\n",
    "    give authorization, you will be redirected to\n",
    "    a url.  Paste that url you were directed to to\n",
    "    complete the authorization.\n",
    "\n",
    "    Opened https://accounts.spotify.com/authorize?scope=playlist-modify-public&redirect_uri=ht...\n",
    "    \n",
    "\n",
    "You need to authenticate your browser session. Follow the link and log in to Spotify. After login, you will be redirected to http://localhost/?code=... Copy the entire URL and paste it to the prompted textbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:54.045000Z",
     "start_time": "2017-08-24T10:20:34.076000Z"
    }
   },
   "outputs": [],
   "source": [
    "token = util.prompt_for_user_token(SPOTIFY_USER, \n",
    "                                   \"playlist-modify-public\", \n",
    "                                   redirect_uri=\"http://localhost/\")\n",
    "\n",
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "Before we can train our models we first have to get some data.\n",
    "\n",
    "## Download Echonest Features from Spotify\n",
    "\n",
    "We use spotipy to access the Spotify API and to download metadata and audio features of Spotify tracks. The following list provides a selection of Spotify playlists of various music genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = [\n",
    "    \n",
    "     {\"name\": \"clubbeats\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXbX3zSzB4MO0\"},\n",
    "     {\"name\": \"softpop\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWTwnEm1IYyoj\"},\n",
    "     {\"name\": \"electropop\",   \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX4uPi2roRUwU\"},\n",
    "     {\"name\": \"rockclassics\", \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWXRqgorJj26U\"},\n",
    "     {\"name\": \"rockhymns\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX4vth7idTQch\"},\n",
    "     {\"name\": \"soft_rock\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX6xOPeSOGone\"},\n",
    "     {\"name\": \"metalcore\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWXIcbzpLauPS\"}, \n",
    "     {\"name\": \"metal\",        \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWWOaP4H0w5b0\"},\n",
    "     {\"name\": \"classic_metal\",\"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX2LTcinqsO68\"},\n",
    "     {\"name\": \"grunge\",       \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX11ghcIxjcjE\"},\n",
    "     {\"name\": \"hiphop\",       \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWVdgXTbYm2r0\"},\n",
    "     {\"name\": \"poppunk\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXa9wYJr1oMFq\"},\n",
    "     {\"name\": \"classic\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXcN1fAVSf7CR\"}\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Playlist meta-data\n",
    "\n",
    "Insted of writing one big loop to download the data, I decided to split it into separate more comprehensible steps.\n",
    "\n",
    "The Spotify API does not return infinite elements, but requires batch processing. The largest batch size is 100 items such as tracks, artists or albums. As a first step we get relevant meta-data for the supplied playlists. Especially the *num_track* property is conveniant for the further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_metadata(spotify_client, playlists):\n",
    "\n",
    "    for playlist in playlists:\n",
    "\n",
    "        # get user and playlist_id from uri\n",
    "        (_,_,user,_,playlist_id) = playlist[\"uri\"].split(\":\")\n",
    "\n",
    "        # retrieve playlist metadat from Spotify\n",
    "        playlist_metadata = spotify_client.user_playlist(user        = user,\n",
    "                                                         playlist_id = playlist_id)\n",
    "\n",
    "        # extract relevant information\n",
    "        playlist[\"user\"]        = user\n",
    "        playlist[\"playlist_id\"] = playlist_id\n",
    "        playlist[\"num_tracks\"]  = playlist_metadata[\"tracks\"][\"total\"]\n",
    "\n",
    "        # initialize fields for further processing\n",
    "        playlist[\"track_ids\"]   = []\n",
    "        \n",
    "    return playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = get_playlist_metadata(sp, playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of our dataset**\n",
    "\n",
    "Now we can already estimate the approximate size of our data-set. The set might contain duplicate tracks from overlapping playlists. Those are removed later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feddafd6978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "playlist_sizes = pd.DataFrame(data  = [playlist[\"num_tracks\"] for playlist in playlists],\n",
    "                              index = [playlist[\"name\"] for playlist in playlists])\n",
    "\n",
    "playlist_sizes.sort_values(0,ascending=False).plot(kind='bar', figsize=(10,4), legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of tracks (including duplicates - will be removed later on)\n",
    "int(playlist_sizes.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get track-ids of all playlist entries\n",
    "\n",
    "To download meta- and feature-data for tracks, we need to fetch the playlist entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_ids(sp, playlists):\n",
    "\n",
    "    # max Spotify batch size\n",
    "    batch_size = 100\n",
    "\n",
    "    # retrieve tracks for each playlist\n",
    "    for playlist in playlists:\n",
    "\n",
    "        # batch processing\n",
    "        for offset in np.arange(0, playlist[\"num_tracks\"], batch_size):\n",
    "\n",
    "            limit = np.min([batch_size, playlist[\"num_tracks\"] - offset])\n",
    "\n",
    "            playlist_entries = sp.user_playlist_tracks(user        = playlist[\"user\"],\n",
    "                                                       playlist_id = playlist[\"playlist_id\"], \n",
    "                                                       limit       = limit, \n",
    "                                                       offset      = offset,\n",
    "                                                       fields      = [\"items\"])\n",
    "\n",
    "            playlist[\"track_ids\"].extend([entry[\"track\"][\"id\"] for entry in playlist_entries[\"items\"]])\n",
    "            \n",
    "    return playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = get_track_ids(sp, playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data and features from Spotify\n",
    "\n",
    "Now it's time to download the dat for our tracks.\n",
    "\n",
    "The features provided by the Spotify API were extracted using the *Echonest Analyzer*. This is a music audio analysis tool developed by the music analysis company the Echonest which was aquired by Spotify in 2014. Music metadata returned by the Analyzer includes artist information (name, user applied tags including weights and term frequencies, a list of similar artists), album information (name, year) and song information (title). Additionally a set of identifiers is provided that can be used to access complimentary metadata repositories (e.g. musicbrainz\\footnote{http://musicbrainz.org}, playme\\footnote{http://www.playme.com},7digital)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching with joblib\n",
    "\n",
    "We will use caching to locally store retrieved data. This is on the one hand a requirement of the API and on the other it speeds up processing when we reload the notebook. *joblib* is a convenient library which simplifies caching.\n",
    "\n",
    "*Update the cachdir to an appropriate path in the following cell*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:32.875000Z",
     "start_time": "2017-08-24T10:20:32.870000Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(cachedir='/home/schindler/tmp/spotify/', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method retrieves meta-data, sequential features such as *MFCCs* and *Chroma*, and track-level features such as *Dancability*. The *@memory.cache* annotation tells *joblib* to persist all return values for the supplied parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_spotify_data(track_id):\n",
    "    \n",
    "    # meta-data\n",
    "    track_metadata      = sp.track(track_id)\n",
    "    album_metadata      = sp.album(track_metadata[\"album\"][\"id\"])\n",
    "    artist_metadata     = sp.artist(track_metadata[\"artists\"][0][\"id\"])\n",
    "    \n",
    "    # feature-data\n",
    "    sequential_features = sp.audio_analysis(track_id)\n",
    "    trackbased_features = sp.audio_features([track_id])\n",
    "    \n",
    "    return track_metadata, album_metadata, artist_metadata, sequential_features, trackbased_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieving data for all tracks**\n",
    "\n",
    "The following loop downloads meta- and feature-data for all tracks. The *processed_track_ids* list is used to avoid duplicated entries. Be aware that downloading a lot of tracks could take some time. Processing 1.000 tracks may take about 15 to 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_track_data(sp, playlists):\n",
    "\n",
    "    num_tracks_total = np.sum([playlist[\"num_tracks\"] for playlist in playlists])\n",
    "    \n",
    "    pbar = progressbar.ProgressBar(max_value=num_tracks_total)\n",
    "    pbar.start()\n",
    "\n",
    "    raw_track_data      = []\n",
    "    processed_track_ids = []\n",
    "\n",
    "    for playlist in playlists:\n",
    "\n",
    "        for track_id in playlist[\"track_ids\"]:\n",
    "\n",
    "            try:\n",
    "                # avoid duplicates in the data-set\n",
    "                if track_id not in processed_track_ids:\n",
    "\n",
    "                    # retrieve data from Spotify\n",
    "                    spotify_data = get_spotify_data(track_id)\n",
    "\n",
    "                    raw_track_data.append([playlist[\"name\"], spotify_data])\n",
    "                    processed_track_ids.append(track_id)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "            pbar.update(len(raw_track_data))\n",
    "            \n",
    "    return raw_track_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9% (101 of 1077) |##                    | Elapsed Time: 0:00:12 ETA:  0:01:39"
     ]
    }
   ],
   "source": [
    "raw_track_data = download_track_data(sp, playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data\n",
    "\n",
    "Currently we only have a list of raw data-objects retrieved from the Spotify API. We need to transform this information to a more structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Meta-data\n",
    "\n",
    "First we aggregate the meta-data. All relevant information is stored in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_metadata(raw_track_data):\n",
    "\n",
    "    metadata = []\n",
    "\n",
    "    for playlist_name, spotify_data in raw_track_data:\n",
    "\n",
    "        track_metadata, album_metadata, artist_metadata, _, _ = spotify_data\n",
    "\n",
    "        # get year of album release\n",
    "        release_date = album_metadata[\"release_date\"]\n",
    "\n",
    "        if album_metadata[\"release_date_precision\"] != \"year\":\n",
    "            release_date = release_date.split(\"-\")[0]\n",
    "\n",
    "        # assamble metadata\n",
    "        metadata.append([track_metadata[\"id\"],\n",
    "                         artist_metadata[\"name\"], \n",
    "                         track_metadata[\"name\"], \n",
    "                         album_metadata[\"name\"],\n",
    "                         album_metadata[\"label\"],\n",
    "                         track_metadata[\"duration_ms\"],\n",
    "                         track_metadata[\"popularity\"],\n",
    "                         release_date,\n",
    "                         artist_metadata[\"genres\"], \n",
    "                         playlist_name])\n",
    "\n",
    "    metadata = pd.DataFrame(metadata, columns=[\"track_id\", \"artist_name\", \"title\", \"album_name\", \n",
    "                                               \"label\", \"duration\", \"popularity\",  \"year\",  \"genres\", \n",
    "                                               \"playlist\"])\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = aggregate_metadata(raw_track_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an example of the aggregated meta-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>34gCuhDGsG4bRPIf9bb02f</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>x (Deluxe Edition)</td>\n",
       "      <td>Atlantic Records UK</td>\n",
       "      <td>281560</td>\n",
       "      <td>87</td>\n",
       "      <td>2014</td>\n",
       "      <td>[pop]</td>\n",
       "      <td>softpop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1HNkqx9Ahdgi1Ixy2xkKkL</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Photograph</td>\n",
       "      <td>x (Deluxe Edition)</td>\n",
       "      <td>Atlantic Records UK</td>\n",
       "      <td>258986</td>\n",
       "      <td>87</td>\n",
       "      <td>2014</td>\n",
       "      <td>[pop]</td>\n",
       "      <td>softpop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5uCax9HTNlzGybIStD3vDh</td>\n",
       "      <td>James Arthur</td>\n",
       "      <td>Say You Won't Let Go</td>\n",
       "      <td>Back from the Edge</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>211466</td>\n",
       "      <td>87</td>\n",
       "      <td>2016</td>\n",
       "      <td>[pop, post-teen pop, talent show]</td>\n",
       "      <td>softpop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3U4isOIWM3VvDubwSI3y7a</td>\n",
       "      <td>John Legend</td>\n",
       "      <td>All of Me</td>\n",
       "      <td>Love In The Future</td>\n",
       "      <td>G.O.O.D. Music/Columbia</td>\n",
       "      <td>269560</td>\n",
       "      <td>86</td>\n",
       "      <td>2013</td>\n",
       "      <td>[neo mellow, neo soul, pop, pop christmas, r&amp;b...</td>\n",
       "      <td>softpop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>51ChrwmUPDJvedPQnIU8Ls</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Dive</td>\n",
       "      <td>รท (Deluxe)</td>\n",
       "      <td>Atlantic Records UK</td>\n",
       "      <td>238440</td>\n",
       "      <td>85</td>\n",
       "      <td>2017</td>\n",
       "      <td>[pop]</td>\n",
       "      <td>softpop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id   artist_name                 title  \\\n",
       "83  34gCuhDGsG4bRPIf9bb02f    Ed Sheeran     Thinking Out Loud   \n",
       "89  1HNkqx9Ahdgi1Ixy2xkKkL    Ed Sheeran            Photograph   \n",
       "80  5uCax9HTNlzGybIStD3vDh  James Arthur  Say You Won't Let Go   \n",
       "92  3U4isOIWM3VvDubwSI3y7a   John Legend             All of Me   \n",
       "98  51ChrwmUPDJvedPQnIU8Ls    Ed Sheeran                  Dive   \n",
       "\n",
       "            album_name                    label  duration  popularity  year  \\\n",
       "83  x (Deluxe Edition)      Atlantic Records UK    281560          87  2014   \n",
       "89  x (Deluxe Edition)      Atlantic Records UK    258986          87  2014   \n",
       "80  Back from the Edge                 Columbia    211466          87  2016   \n",
       "92  Love In The Future  G.O.O.D. Music/Columbia    269560          86  2013   \n",
       "98          รท (Deluxe)      Atlantic Records UK    238440          85  2017   \n",
       "\n",
       "                                               genres playlist  \n",
       "83                                              [pop]  softpop  \n",
       "89                                              [pop]  softpop  \n",
       "80                  [pop, post-teen pop, talent show]  softpop  \n",
       "92  [neo mellow, neo soul, pop, pop christmas, r&b...  softpop  \n",
       "98                                              [pop]  softpop  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.sort_values(\"popularity\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Feature Data\n",
    "\n",
    "\n",
    "Further information provided by the Spotify API is based on audio signal analysis. Two major sets of audio features are provided describing timbre and pitch information of the corresponding music track. The features are extracted using onset detection to segment the audio based on music events. These *Segments* are described as sound entities that are relative uniform in timbre and harmony and are the basis for further feature extraction. For each *Segment* the following features are derived from musical audio signals:\n",
    "\n",
    "* **Segments Timbre** are casually described as MFCC-like features. A 12 dimensional vector with unbounded values centered around 0 representing a high level abstraction of the spectral surface.\n",
    "* **Segments Pitches** are casually described as Chroma-like features. A normalized 12 dimensional vector ranging from 0 to 1 corresponding to the 12 pitch classes C, C#, to B.\n",
    "* **Segments Loudness Max** represents the peak loudness value within each segment.\n",
    "* **Segments Loudness Max Time** describes the offset within the segment of the point of maximum loudness.\n",
    "* **Segments Start** provide start time information of each segment/onset.\n",
    "\n",
    "Additionally a set of high-level features provided on a global track-level:\n",
    "\n",
    "* **Tempo** measured in beats per minute\n",
    "* **Time Signature** three or four quater stroke\n",
    "* **Danceability** a value between 0 and 1 measuring of how danceable this song is \n",
    "* **Energy** a value between 0 and 1 measuring the perceived energy of a song\n",
    "* **acousticness** does the track only use acoustic instruments?\n",
    "* **danceability** can you dance to this track?\n",
    "* **instrumentalnes** is there somebody singing?\n",
    "* **liveness** live or studio version?\n",
    "* **speechiness** rap music or singing?\n",
    "* **valence** aggressive or calm?\n",
    "\n",
    "I performed a detailed evaluation of the Echonest Feature-sets and how to effectively aggregate the provided information for Music Information Retrieval Experiments on the Million Song Dataset. The results are published in the following article:\n",
    "\n",
    "* *Alexander Schindler and Andreas Rauber. [Capturing the temporal domain in echonest features for improved classification effectiveness](http://www.ifs.tuwien.ac.at/%7Eschindler/pubs/AMR2012.pdf). In Adaptive Multimedia Retrieval, Lecture Notes in Computer Science, Copenhagen, Denmark, October 24-25 2012. Springer.*\n",
    "\n",
    "### Single Vector Representation\n",
    "\n",
    "The simlarity retrieval approach presented in this tutorial is based on a vector-space model where each track is represented of a single fixed-length feature vector. The segment-based features provided by the Spotify API are lists of feature vectors of varying lengths. Thus, these features need to be aggregated into a single feature vector. The following function describes a simple approach to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:58:50.844000Z",
     "start_time": "2017-08-24T12:58:50.830000Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_features(seq_data, track_data, metadata, with_year=False, with_popularity=False):\n",
    "\n",
    "    calc_statistical_moments = lambda x: np.concatenate([x.mean(axis=0), x.std(axis=0)])\n",
    "    \n",
    "    # sequential data\n",
    "    segments = seq_data[\"segments\"]\n",
    "    sl       = len(segments)\n",
    "    \n",
    "    # MFCCs - 24 dimensions\n",
    "    mfcc              = np.array([s[\"timbre\"] for s in segments])\n",
    "    mfcc              = calc_statistical_moments(mfcc)\n",
    "    \n",
    "    # Chroma / pitch classes - 24 dimensions\n",
    "    chroma            = np.array([s[\"pitches\"] for s in segments])\n",
    "    chroma            = calc_statistical_moments(chroma)\n",
    "    \n",
    "    # maximum loudness values per segment - 2 dimensions\n",
    "    loudness_max      = np.array([s[\"loudness_max\"] for s in segments]).reshape((sl,1))\n",
    "    loudness_max      = calc_statistical_moments(loudness_max)\n",
    "    \n",
    "    # offset of max loudness value within segment - 2 dimensions\n",
    "    loudness_start    = np.array([s[\"loudness_start\"] for s in segments]).reshape((sl,1))\n",
    "    loudness_start    = calc_statistical_moments(loudness_start)\n",
    "    \n",
    "    # length of max loudness values within segment - 2 dimensions\n",
    "    loudness_max_time = np.array([s[\"loudness_max_time\"] for s in segments]).reshape((sl,1))\n",
    "    loudness_max_time = calc_statistical_moments(loudness_max_time)\n",
    "    \n",
    "    # length of segment - 2 dimensions\n",
    "    duration          = np.array([s[\"duration\"] for s in segments]).reshape((sl,1))\n",
    "    duration          = calc_statistical_moments(duration)\n",
    "    \n",
    "    # confidence of segment boundary detection - 2 dimensions\n",
    "    confidence        = np.array([s[\"confidence\"] for s in segments]).reshape((sl,1))\n",
    "    confidence        = calc_statistical_moments(confidence)\n",
    "    \n",
    "    # concatenate sequential features\n",
    "    sequential_features = np.concatenate([mfcc, chroma, loudness_max, loudness_start, \n",
    "                                          loudness_max_time, duration, confidence], axis=0)\n",
    "    \n",
    "    # track-based data\n",
    "    track_features = [track_data[0][\"acousticness\"],     # acoustic or not?\n",
    "                      track_data[0][\"danceability\"],     # danceable?\n",
    "                      track_data[0][\"energy\"],           # energetic or calm?\n",
    "                      track_data[0][\"instrumentalness\"], # is somebody singing?\n",
    "                      track_data[0][\"liveness\"],         # live or studio?\n",
    "                      track_data[0][\"speechiness\"],      # rap or singing?\n",
    "                      track_data[0][\"tempo\"],            # slow or fast?\n",
    "                      track_data[0][\"time_signature\"],   # 3/4, 4/4, 6/8, etc.\n",
    "                      track_data[0][\"valence\"]]          # happy or sad?\n",
    "    \n",
    "    if with_year:\n",
    "        track_features.append(int(metadata[\"year\"]))\n",
    "        \n",
    "    if with_popularity:\n",
    "        track_features.append(int(metadata[\"popularity\"]))\n",
    "        \n",
    "    \n",
    "    return np.concatenate([sequential_features, track_features], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afgregate all features of the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_featuredata(raw_track_data):\n",
    "\n",
    "    feature_data = []\n",
    "\n",
    "    for i, (_, spotify_data) in enumerate(raw_track_data):\n",
    "\n",
    "        _, _, _, f_sequential, f_trackbased = spotify_data\n",
    "\n",
    "        feature_vec = aggregate_features(f_sequential, \n",
    "                                         f_trackbased, \n",
    "                                         metadata.iloc[i], \n",
    "                                         with_year       = True, \n",
    "                                         with_popularity = True)    \n",
    "\n",
    "        feature_data.append(feature_vec)\n",
    "\n",
    "    return np.asarray(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:38:34.716000Z",
     "start_time": "2017-08-24T10:38:34.703000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_data.shape: (101, 69)\n"
     ]
    }
   ],
   "source": [
    "feature_data = aggregate_featuredata(raw_track_data)\n",
    "\n",
    "print(\"feature_data.shape:\", feature_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize feature data\n",
    "\n",
    "The feature vectors are composed of differnt feature-sets. All of them with different value ranges. While features such as Acousticness and Danceability are scaled between 0 and 1, the BPM values of the tempo feature ranges around 120 or higher. We apply Standard Score or Zero Mean and Unit Variance normalization to uniformly scale the value ranges of the features.\n",
    "\n",
    "$$\n",
    "z = {x- \\mu \\over \\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize sequential_features\n",
    "feature_data -= feature_data.mean(axis=0)\n",
    "feature_data /= feature_data.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Similarities\n",
    "\n",
    "This section describes the fundamentals of the content-based audio similarity search approach followed in this tutorial. Audio features are descriptive numbers calculated from the audio spectrum of a track. A good example is the Spectral Centroid, which can be interpreted as the center of gravity of an audio recording. It describes the average frequency weighted by its intensity and distinguishes brighter from darker sounds. Such features are usually calculated for several intervals of a track and finally aggregated into a single vector representation. The latter step, which is a requirement for many machine/statistical learning tasks, is accomplished by calculating statistical measures such as mean, standard deviation, etc.\n",
    "\n",
    "In the following example, the Spectral Centroids of 10 different tracks are provided using their mean and standard deviation aggregations. Thus, the Spectral Centroid feature(-set) is represented by a two-dimensional feature vector such as the following example:\n",
    "\n",
    "    ID   Mean                  Standard Deviation\n",
    "    0    1517.5993814237531    291.1855836731788\n",
    "\n",
    "In this example the center frequency is 1518 Hz and it deviates by 291 Hz. These numbers already describe the audio content and can be used to find similar tracks. The common approach to calcualte music similarity from audio content is based on vector difference. The assumption is, that similar audio feature-values correspond with similar audio content. Thus, feature vectors with smaller vector differences correspond to more similar tracks. The following data represents the extracted Spectral Centroids of our 10-tracks collection:\n",
    "\n",
    "\n",
    "    ID   Mean                  Standard Deviation\n",
    "    0    1517.5993814237531    291.1855836731788\n",
    "    1    1659.1988993873124    327.64811981777865\n",
    "    2    1507.4617047141264    340.8830079395701\n",
    "    3    1597.6019371942953    507.1007933367403\n",
    "    4    1498.8531206911534    288.3780838480238\n",
    "    5    535.5910732230583     89.90893994909047\n",
    "    6    2261.4032345595674    353.5971736260454\n",
    "    7    2331.881852844861     406.33517225264194\n",
    "    8    1868.690426450363     342.7489751514078\n",
    "    9    2204.6324484864085    328.94334883095553\n",
    "\n",
    "The tracks have unique identifiers and we are using the track with ID 5 to search for similar items. This step requires a similarity metric, which defines how the vector distance has to be calculated as a single numeric value. The most common choices are the Manhattan (L1) and Euclidean (L2) distance measures. The Euclidean Distance is the square root of the sum of squared differences of two vectors.\n",
    "To calculate the Euclidean Distance between track 5 and track 0:\n",
    "\n",
    "    ID   Mean                  Standard Deviation\n",
    "    0    1517.5993814237531    291.1855836731788\n",
    "    5    535.5910732230583     89.90893994909047\n",
    "\n",
    "we first compute the difference between the values of each vectors\n",
    "\n",
    "    982.008308           201.276644\n",
    "\n",
    "square them to get the absolute magnitude:\n",
    "\n",
    "    964340.317375        40512.287309\n",
    "\n",
    "and take the sum of these values:\n",
    "\n",
    "    1004852.6046840245\n",
    "\n",
    "Per definition the square root has to be calculated from the sum, but this step is normally skipped because it does not alter the ranking and is processing intensive. By calculating the distance for all items in the collection, we retrieve a list of distance values where the smaller distances correspond to more similar audio content and the higher values should sound more dissimilar.\n",
    "\n",
    "    ID   Distance\n",
    "    0    1004852.6046840245\n",
    "    1    1319014.4646621975\n",
    "    2    1007520.5071585375\n",
    "    3    1301916.1177259558\n",
    "    4    967263.7731724023\n",
    "    5    0.0\n",
    "    6    3047959.100796666\n",
    "    7    3326786.1254441254\n",
    "    8    1841081.968976167\n",
    "    9    2842836.5609704787\n",
    "\n",
    "To retrieve a ranked list of similar sounding tracks, the list of vector distances has to be ordered ascendingly.\n",
    "\n",
    "    ID   Distance\n",
    "    5    0.0\n",
    "    4    967263.7731724023\n",
    "    0    1004852.6046840245\n",
    "    2    1007520.5071585375\n",
    "    3    1301916.1177259558\n",
    "    1    1319014.4646621975\n",
    "    8    1841081.968976167\n",
    "    9    2842836.5609704787\n",
    "    6    3047959.100796666\n",
    "    7    3326786.1254441254\n",
    "\n",
    "This so called vector space model is predominant in content based multimedia retrieval. The most crucial and problematic part is feature crafting, meaning that in the case in which the extracted numbers do not describe the audio well enough, the vector based similarity will also fail to provide results that are perceived as similar.\n",
    "The described approach requires the availability of all feature vectors of all items of a collection. Thus, the feature vectors must be stored. No matter which retrieval approach (pre-calculated / indexed / on demand) will be chosen, all features will be required at a certain time. Given that the feature extraction is an computationally expensive task (in terms of processing resources and total time), the extracted features are stored and made accessible using a common data format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "\n",
    "In the final part of this tutorial we wil use the Euclidean Distance to calculate similarities between tracks. As mentioned above, the Euclidean Distance is a metric to calculate the distance between two vectors and thus is a function of dissimilarity. This means, vectors with smaller distance values are more similar than those with higher distances.\n",
    "\n",
    "$$\n",
    "d(p,q) = \\sqrt{\\sum_{i=1}^n (q_i-p_i)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucledian_distance(feature_space, query_vector):\n",
    "    \n",
    "    return np.sqrt(np.sum((feature_space - query_vector)**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the rest of the tutorial we will use this song to demonstrate the results of the approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1bKii6cdjoqMAuAWJGZ8oi</td>\n",
       "      <td>TV Noise</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>Spinnin' Premium</td>\n",
       "      <td>160000</td>\n",
       "      <td>47</td>\n",
       "      <td>2018</td>\n",
       "      <td>[deep big room, electro house]</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id artist_name      title album_name  \\\n",
       "33  1bKii6cdjoqMAuAWJGZ8oi    TV Noise  Milkshake  Milkshake   \n",
       "\n",
       "               label  duration  popularity  year  \\\n",
       "33  Spinnin' Premium    160000          47  2018   \n",
       "\n",
       "                            genres   playlist  \n",
       "33  [deep big room, electro house]  clubbeats  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_track_idx = 33\n",
    "\n",
    "metadata.loc[[query_track_idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code implement the approach described above. First, the distances between the query vector and all other vectors of the collection are calculated. Then the distances are sorted ascnedingly to get the simlar tracks. Because the metric distance of identical vectors is 0, the top-most entry of the sorted list is always the query track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TV Noise</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>James Hype</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Phlegmatic Dogs</td>\n",
       "      <td>Westcoaster</td>\n",
       "      <td>Westcoaster</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JACKHAD</td>\n",
       "      <td>Get Money - Radio Edit</td>\n",
       "      <td>Get Money</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Spock</td>\n",
       "      <td>Digital War</td>\n",
       "      <td>Digital War</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Garmiani</td>\n",
       "      <td>Fogo</td>\n",
       "      <td>Fogo</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>KSHMR</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barkley</td>\n",
       "      <td>Say</td>\n",
       "      <td>Say</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chimp &amp; Panse</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Dylan Taylor</td>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sagan</td>\n",
       "      <td>We Are Lost</td>\n",
       "      <td>We Are Lost</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist_name                                  title  \\\n",
       "33         TV Noise                              Milkshake   \n",
       "30       James Hype  More Than Friends (feat. Kelli-Leigh)   \n",
       "56  Phlegmatic Dogs                            Westcoaster   \n",
       "26          JACKHAD                 Get Money - Radio Edit   \n",
       "73            Spock                            Digital War   \n",
       "45         Garmiani                                   Fogo   \n",
       "70            KSHMR                                Kolkata   \n",
       "11          Barkley                                    Say   \n",
       "1     Chimp & Panse                                    One   \n",
       "36     Dylan Taylor                           Frankenstein   \n",
       "29            Sagan                            We Are Lost   \n",
       "\n",
       "                               album_name  year   playlist  \n",
       "33                              Milkshake  2018  clubbeats  \n",
       "30  More Than Friends (feat. Kelli-Leigh)  2017  clubbeats  \n",
       "56                            Westcoaster  2017  clubbeats  \n",
       "26                              Get Money  2018  clubbeats  \n",
       "73                            Digital War  2017  clubbeats  \n",
       "45                                   Fogo  2017  clubbeats  \n",
       "70                                Kolkata  2017  clubbeats  \n",
       "11                                    Say  2018  clubbeats  \n",
       "1                                     One  2017  clubbeats  \n",
       "36                           Frankenstein  2018  clubbeats  \n",
       "29                            We Are Lost  2018  clubbeats  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the distance between the query-vector and all others\n",
    "dist = eucledian_distance(feature_data, feature_data[query_track_idx])\n",
    "\n",
    "# sort the distances ascendingly - use sorted index\n",
    "sorted_idx = np.argsort(dist)\n",
    "\n",
    "# display top-10 results (first track = query track)\n",
    "display_cols = [\"artist_name\", \"title\", \"album_name\", \"year\", \"playlist\"]\n",
    "\n",
    "metadata.loc[sorted_idx[:11], display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Eucledian Distance\n",
    "\n",
    "The approach taken to combine the different feature-sets is refered to as early fusion. The problem with the approach described in the previous step is, that larger feature-sets dominate the calculated distance values. The aggregated MFCC and Chroma features have 24 dimensions each. Together they have more dimensions as the remaining features which are mostly single dimensional features. Thus, the distances are unequally dominated by the two feature sets.\n",
    "\n",
    "To avoid such a bias, we scale the feature-space such that feature-sets and single-value features have euqal the same weights and thus euqal influence on the resulting distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-set lengths and order\n",
    "featureset_lengths = [24, # mfcc\n",
    "                      24, # chroma\n",
    "                      2,  # loudness_max\n",
    "                      2,  # loudness_start\n",
    "                      2,  # loudness_max_time\n",
    "                      2,  # sequence length\n",
    "                      2,  # confidence\n",
    "                      1,  # acousticness\n",
    "                      1,  # danceability\n",
    "                      1,  # energy\n",
    "                      1,  # instrumentalness\n",
    "                      1,  # liveness\n",
    "                      1,  # speechiness\n",
    "                      1,  # tempo\n",
    "                      1,  # time_signature\n",
    "                      1,  # valence\n",
    "                      1,  # year\n",
    "                      1]  # popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_eucledian_distance(feature_space, query_vector):\n",
    "    \n",
    "    distances = (feature_space - query_vector)**2\n",
    "    \n",
    "    # feature_start_idx\n",
    "    start_idx = 0 \n",
    "    \n",
    "    # normalize distances\n",
    "    for sequence_length in featureset_lengths:\n",
    "        \n",
    "        # feature_stop_idx\n",
    "        stop_idx                         = start_idx + sequence_length\n",
    "        distances[:,start_idx:stop_idx] /= distances[:,start_idx:stop_idx].sum(axis=1).max()\n",
    "        start_idx                        = stop_idx\n",
    "    \n",
    "    return np.sqrt(np.sum(distances, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TV Noise</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>James Hype</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JACKHAD</td>\n",
       "      <td>Get Money - Radio Edit</td>\n",
       "      <td>Get Money</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Phlegmatic Dogs</td>\n",
       "      <td>Westcoaster</td>\n",
       "      <td>Westcoaster</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sagan</td>\n",
       "      <td>We Are Lost</td>\n",
       "      <td>We Are Lost</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Felon</td>\n",
       "      <td>Trill Witcha</td>\n",
       "      <td>Trill Witcha</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J Balvin</td>\n",
       "      <td>Mi Gente - Hardwell &amp; Quintino Remix</td>\n",
       "      <td>Mi Gente (Hardwell &amp; Quintino Remix)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Garmiani</td>\n",
       "      <td>Fogo</td>\n",
       "      <td>Fogo</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DNF x I.GOT.U</td>\n",
       "      <td>Sick - Radio Edit</td>\n",
       "      <td>Sick</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>KSHMR</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Calvin Logue</td>\n",
       "      <td>Warrior</td>\n",
       "      <td>Warrior EP</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist_name                                  title  \\\n",
       "33         TV Noise                              Milkshake   \n",
       "30       James Hype  More Than Friends (feat. Kelli-Leigh)   \n",
       "26          JACKHAD                 Get Money - Radio Edit   \n",
       "56  Phlegmatic Dogs                            Westcoaster   \n",
       "29            Sagan                            We Are Lost   \n",
       "64            Felon                           Trill Witcha   \n",
       "3          J Balvin   Mi Gente - Hardwell & Quintino Remix   \n",
       "45         Garmiani                                   Fogo   \n",
       "6     DNF x I.GOT.U                      Sick - Radio Edit   \n",
       "70            KSHMR                                Kolkata   \n",
       "10     Calvin Logue                                Warrior   \n",
       "\n",
       "                               album_name  year   playlist  \n",
       "33                              Milkshake  2018  clubbeats  \n",
       "30  More Than Friends (feat. Kelli-Leigh)  2017  clubbeats  \n",
       "26                              Get Money  2018  clubbeats  \n",
       "56                            Westcoaster  2017  clubbeats  \n",
       "29                            We Are Lost  2018  clubbeats  \n",
       "64                           Trill Witcha  2017  clubbeats  \n",
       "3    Mi Gente (Hardwell & Quintino Remix)  2017  clubbeats  \n",
       "45                                   Fogo  2017  clubbeats  \n",
       "6                                    Sick  2017  clubbeats  \n",
       "70                                Kolkata  2017  clubbeats  \n",
       "10                             Warrior EP  2018  clubbeats  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = scaled_eucledian_distance(feature_data, feature_data[query_track_idx])\n",
    "\n",
    "metadata.loc[np.argsort(dist)[:11], display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Weighting\n",
    "\n",
    "As explained above, the vanilla Eucliden Distance in an early fusion approach is dominated by large feature-sets. Through scaling the feature-space we achieved equal influence for all feature-sets and features. Now, equal influence is not always the best choice fo music similarity. For example, the year and popularity feature we included into our feature vector are not an intrinsic music property. We just added them to cluster recordings of the same epoch together. Currently this feature has the same impact on the estimated similarity as timbre, rhythm and harmonics. When using many features it is commonly a good choice to apply different weights to them. Estimating these weights is generally achieved empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-set lengths and order\n",
    "featureset_weights = [1.55,  # mfcc\n",
    "                      0.6,  # chroma\n",
    "                      0.8,  # loudness_max\n",
    "                      0.5,  # loudness_start\n",
    "                      0.5,  # loudness_max_time\n",
    "                      2.5,  # sequence length\n",
    "                      0.5,  # confidence\n",
    "                      0.5,  # acousticness\n",
    "                      0.5,  # danceability\n",
    "                      1.5,  # energy\n",
    "                      0.0,  # instrumentalness\n",
    "                      0.0,  # liveness\n",
    "                      0.1,  # speechiness\n",
    "                      0.1,  # tempo\n",
    "                      0.9,  # time_signature\n",
    "                      0.1,  # valence\n",
    "                      5.5,  # year\n",
    "                      0.4]  # popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_eucledian_distance(feature_space, query_vector, featureset_weights):\n",
    "    \n",
    "    distances = (feature_space - query_vector)**2\n",
    "    \n",
    "    # feature_start_idx\n",
    "    start_idx = 0 \n",
    "    \n",
    "    # normalize distances\n",
    "    for sequence_length, weight in zip(featureset_lengths, featureset_weights):\n",
    "\n",
    "        # feature_stop_idx\n",
    "        stop_idx                         = start_idx + sequence_length\n",
    "        distances[:,start_idx:stop_idx] /= distances[:,start_idx:stop_idx].sum(axis=1).max()\n",
    "        distances[:,start_idx:stop_idx] *= weight\n",
    "        start_idx                        = stop_idx\n",
    "\n",
    "    return np.sqrt(np.sum(distances, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TV Noise</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>Milkshake</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JACKHAD</td>\n",
       "      <td>Get Money - Radio Edit</td>\n",
       "      <td>Get Money</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>James Hype</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Phlegmatic Dogs</td>\n",
       "      <td>Westcoaster</td>\n",
       "      <td>Westcoaster</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Spock</td>\n",
       "      <td>Digital War</td>\n",
       "      <td>Digital War</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sagan</td>\n",
       "      <td>We Are Lost</td>\n",
       "      <td>We Are Lost</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chimp &amp; Panse</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>KSHMR</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Opiuo</td>\n",
       "      <td>Botrok</td>\n",
       "      <td>Botrok</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Felon</td>\n",
       "      <td>Trill Witcha</td>\n",
       "      <td>Trill Witcha</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barkley</td>\n",
       "      <td>Say</td>\n",
       "      <td>Say</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist_name                                  title  \\\n",
       "33         TV Noise                              Milkshake   \n",
       "26          JACKHAD                 Get Money - Radio Edit   \n",
       "30       James Hype  More Than Friends (feat. Kelli-Leigh)   \n",
       "56  Phlegmatic Dogs                            Westcoaster   \n",
       "73            Spock                            Digital War   \n",
       "29            Sagan                            We Are Lost   \n",
       "1     Chimp & Panse                                    One   \n",
       "70            KSHMR                                Kolkata   \n",
       "50            Opiuo                                 Botrok   \n",
       "64            Felon                           Trill Witcha   \n",
       "11          Barkley                                    Say   \n",
       "\n",
       "                               album_name  year   playlist  \n",
       "33                              Milkshake  2018  clubbeats  \n",
       "26                              Get Money  2018  clubbeats  \n",
       "30  More Than Friends (feat. Kelli-Leigh)  2017  clubbeats  \n",
       "56                            Westcoaster  2017  clubbeats  \n",
       "73                            Digital War  2017  clubbeats  \n",
       "29                            We Are Lost  2018  clubbeats  \n",
       "1                                     One  2017  clubbeats  \n",
       "70                                Kolkata  2017  clubbeats  \n",
       "50                                 Botrok  2017  clubbeats  \n",
       "64                           Trill Witcha  2017  clubbeats  \n",
       "11                                    Say  2018  clubbeats  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = weighted_eucledian_distance(feature_data, feature_data[query_track_idx], featureset_weights)\n",
    "\n",
    "metadata.loc[np.argsort(dist)[:11], display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "So far we have only tested our similarity retrieval algorithms on a few single examples. To evaluate, if the presented approaches perform differently, we perform a full evaluation. To estimate the performance we measure precision and recall of our algorithms. These are standard information retrieval measures of relevance. In the context of this tutorial **precision** measures how many tracks of a given resultlist belong to the same playlist as the query song (relative to the length of the resultlist). **Recall** measures how many tracks of the query song's playlist are contained in the resultlist (relative to the length of the playlist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(similarity_function, cut_off):\n",
    "\n",
    "    all_precisions = []\n",
    "    all_recall     = []\n",
    "\n",
    "    for idx in metadata.index.values:\n",
    "\n",
    "        dist           = similarity_function(feature_data, feature_data[idx])\n",
    "        similar_tracks = metadata.loc[np.argsort(dist)[:cut_off]]\n",
    "        same_label     = similar_tracks[\"playlist\"] == metadata.loc[idx, \"playlist\"]\n",
    "        precision      = same_label.sum() / float(cut_off)\n",
    "        all_precisions.append(precision)\n",
    "        \n",
    "        recall = float(same_label.sum()) / metadata[metadata.playlist == metadata.loc[idx, \"playlist\"]].shape[0]\n",
    "        all_recall.append(recall)\n",
    "\n",
    "    all_precisions = np.array(all_precisions)\n",
    "    all_recall     = np.array(recall)\n",
    "\n",
    "    return all_precisions.mean(), all_recall.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the evauation for all three introduced algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'dict_values' and 'dict_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ed6dabfc2d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mevaluation_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/python2/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   3632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m             indexer = nargsort(k, kind=kind, ascending=ascending,\n\u001b[0;32m-> 3634\u001b[0;31m                                na_position=na_position)\n\u001b[0m\u001b[1;32m   3635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3636\u001b[0m         new_data = self._data.take(indexer,\n",
      "\u001b[0;32m~/anaconda/python2/envs/py36/lib/python3.6/site-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mnargsort\u001b[0;34m(items, kind, ascending, na_position)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mnon_nans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mnon_nan_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_nans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'dict_values' and 'dict_values'"
     ]
    }
   ],
   "source": [
    "cut_off = 20\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "# run evaluation\n",
    "\n",
    "evaluation_results[\"Eucledian Distance\"] = \\\n",
    "    evaluate(lambda x,y: eucledian_distance(x,y), cut_off)\n",
    "    \n",
    "evaluation_results[\"Scaled Eucledian Distance\"] = \\\n",
    "    evaluate(lambda x,y: scaled_eucledian_distance(x,y), cut_off)\n",
    "\n",
    "evaluation_results[\"Weighted Eucledian Distance\"] = \\\n",
    "    evaluate(lambda x,y: weighted_eucledian_distance(x,y, featureset_weights), cut_off)\n",
    "\n",
    "# aggregate results\n",
    "evaluation_results = pd.DataFrame(data  = evaluation_results.values(), \n",
    "                                  index = evaluation_results.keys(), \n",
    "                                  columns=[\"precision\", \"recall\"])\n",
    "\n",
    "# results\n",
    "evaluation_results.sort_values(\"precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results must be interpreted in relation to the analyzed data-set and the method how the metrics are measured. We measure how many tracks in the resulting list of similar songs belong to the same playlist of the query song. We have chosen genre-related playlists such as *Metal* and *Hip-Hop*. But there are also overalpping playlists such as *Classic Metal* and *Rock Hymns* which both contain Rock and Metal tracks. This should be considered in the interpretation of the evaluation results. To get more reliable results, more efforts need to be put into creating better non-overlapping playlists. But, since music similarity is subject to subjective interpretation, this is a challinging task.\n",
    "\n",
    "Although we have a small bias from the overlapping playlists, we see that it makes sense to tune the weights of the features to regulate their impact on the final results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this part of the tutorial I have demonstrated how to access the Spotify to download meta- and feature-data to estimate similarities between songs. The presented method is a content-based approach which calculate similarities based on numerical vector distances.\n",
    "\n",
    "The approach has been chosen due to its simplicity. There is a lot of room for improvements, but this would have made the code examples more complex and the tutorial much longer. To improve the performance, you can consider the following improvements:\n",
    "\n",
    "* **Feature aggregation:** taking only mean and standard deviation is not the most efficient way to aggregate the sequential features provided by the Spotify API.\n",
    "* **Distance Measure:** other distance measures could yield better results. This often depends on the underlying dataset.\n",
    "* **Better Machine Learning Methods:** the presented nearest neighobr based approach is a linear model and is not able to model non-linearities of music similarities.\n",
    "\n",
    "In the next part of this tutorial series I will introduce Siamese Netowkrs. These Deep Neural Networks are able to learn high-level features from the low-level features as well as to learn the non-linear distance function to estimate the similarity between two tracks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notify_time": "5",
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
